{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Coding attention mechanism\n",
        "* Here we will code attention mechanism from scratch.\n",
        "* We will code the following attention mechanism:\n",
        "    1. Self Attention\n",
        "    2. Causal Attention\n",
        "* Let's first start with self attention.\n"
      ],
      "metadata": {
        "id": "FE0UEapsJhm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Self Attention\n",
        "* Here we will use the following example as our example: \"The dog chased the rabbit\""
      ],
      "metadata": {
        "id": "0mpw6wOPKXDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "input = torch.tensor(\n",
        "    [\n",
        "        [0.86,0.97,0.89],#The\n",
        "        [0.56,0.40,0.67],#dog\n",
        "        [0.33,0.82,0.55],#chased\n",
        "        [0.19,0.38,0.85],#the\n",
        "        [0.25,0.36,0.88]#rabbit\n",
        "    ]\n",
        ")\n",
        "print(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA8HVK6wKj9c",
        "outputId": "0f4980ff-2dc7-450a-a1fd-b7223faabfe3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8600, 0.9700, 0.8900],\n",
            "        [0.5600, 0.4000, 0.6700],\n",
            "        [0.3300, 0.8200, 0.5500],\n",
            "        [0.1900, 0.3800, 0.8500],\n",
            "        [0.2500, 0.3600, 0.8800]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Let's assume the above tensor is the embedding of our input sentence.\n",
        "* In the attention mechanism, each token embedding in the sequence is projected into its corresponding query, key, and value vectors by multiplying the embedding with the respective query, key, and value matrices.\n",
        "* The query, key, and value projection matrices are parameters of the model that are learned during training.\n",
        "* Here we will generate our our own query,key and value matrices.\n"
      ],
      "metadata": {
        "id": "T_DhXlcmLU3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_query = torch.randn(3,3)\n",
        "w_key = torch.randn(3,3)\n",
        "w_value = torch.randn(3,3)\n",
        "print(w_query)\n",
        "print(w_key)\n",
        "print(w_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wubQfij-MoSC",
        "outputId": "67d5cade-2b3d-4da8-b9cf-5163de3158c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3472,  1.5337, -1.2087],\n",
            "        [ 1.0625,  0.9326, -0.3823],\n",
            "        [ 0.2039, -0.9414,  0.9970]])\n",
            "tensor([[ 1.6860, -0.9125,  1.8669],\n",
            "        [ 0.7066, -0.7550,  0.6424],\n",
            "        [-0.3040, -0.0108,  0.8090]])\n",
            "tensor([[-0.4256, -1.4681,  0.3927],\n",
            "        [-0.5141,  1.2863, -0.1176],\n",
            "        [-0.7740, -0.3166, -0.5723]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now since we have the weight matrices, let's now compute query,key and value vectors, by computing the dot product of the these matrices with each token."
      ],
      "metadata": {
        "id": "luuCRQHROD0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_vectors = torch.matmul(input, w_query)\n",
        "key_vectors = torch.matmul(input, w_key)\n",
        "value_vectors = torch.matmul(input, w_value)\n",
        "\n",
        "print(\"Query vectors:\")\n",
        "print(query_vectors)\n",
        "print(\"\\nKey vectors:\")\n",
        "print(key_vectors)\n",
        "print(\"\\nValue vectors:\")\n",
        "print(value_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A-uQ2djN_fv",
        "outputId": "e804c19e-77f0-42c7-839e-29deac48fef0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query vectors:\n",
            "tensor([[ 1.5107,  1.3857, -0.5229],\n",
            "        [ 0.7560,  0.6011, -0.1617],\n",
            "        [ 1.0980,  0.7531, -0.1639],\n",
            "        [ 0.6430, -0.1544,  0.4726],\n",
            "        [ 0.6487, -0.1093,  0.4376]])\n",
            "\n",
            "Key vectors:\n",
            "tensor([[ 1.8649, -1.5266,  2.9487],\n",
            "        [ 1.0232, -0.8202,  1.8445],\n",
            "        [ 0.9686, -0.9261,  1.5878],\n",
            "        [ 0.3305, -0.4694,  1.2865],\n",
            "        [ 0.4084, -0.5094,  1.4099]])\n",
            "\n",
            "Value vectors:\n",
            "tensor([[-1.5536, -0.2967, -0.2857],\n",
            "        [-0.9626, -0.5198, -0.2106],\n",
            "        [-0.9877,  0.3961, -0.2816],\n",
            "        [-0.9342, -0.0593, -0.4565],\n",
            "        [-0.9726, -0.1826, -0.4478]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c0b6788"
      },
      "source": [
        "* The next step is to calculate the attention scores. This is done by taking the dot product of the query vector for each token with the key vectors of all other tokens.\n",
        "* The resulting matrix will show how much attention each token should pay to every other token in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fed7d2f",
        "outputId": "b08c990e-b662-4290-d32f-fbaad1022452"
      },
      "source": [
        "attention_scores = torch.matmul(query_vectors, key_vectors.transpose(-2,-1))\n",
        "\n",
        "print(\"Attention Scores:\")\n",
        "print(attention_scores)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Scores:\n",
            "tensor([[-0.8400, -0.5553, -0.6502, -0.8240, -0.8262],\n",
            "        [ 0.0153, -0.0178, -0.0812, -0.2404, -0.2255],\n",
            "        [ 0.4146,  0.2034,  0.1058, -0.2016, -0.1664],\n",
            "        [ 2.8285,  1.6563,  1.5163,  0.8930,  1.0076],\n",
            "        [ 2.6671,  1.5606,  1.4245,  0.8287,  0.9376]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To prevent large dot products from destablizig gradient we scale the attention scores:"
      ],
      "metadata": {
        "id": "IVsUe7r4TUi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_scores = attention_scores / torch.sqrt(torch.tensor(3.0))\n",
        "scaled_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iks1BrtWTgT9",
        "outputId": "ac879194-dc37-45ee-fb2b-ac6b55d3e279"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4850, -0.3206, -0.3754, -0.4757, -0.4770],\n",
              "        [ 0.0088, -0.0103, -0.0469, -0.1388, -0.1302],\n",
              "        [ 0.2393,  0.1174,  0.0611, -0.1164, -0.0961],\n",
              "        [ 1.6330,  0.9562,  0.8754,  0.5156,  0.5817],\n",
              "        [ 1.5399,  0.9010,  0.8224,  0.4784,  0.5413]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Next we convert these scores in probabilities where apply softmax row-wise"
      ],
      "metadata": {
        "id": "LoZdrjZmTynk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = torch.softmax(scaled_scores,dim=-1)\n",
        "attention_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3__ueIqOT7XH",
        "outputId": "017c28fc-4545-43f5-87b7-0a096073198c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1883, 0.2219, 0.2101, 0.1900, 0.1898],\n",
              "        [0.2146, 0.2105, 0.2030, 0.1851, 0.1867],\n",
              "        [0.2417, 0.2139, 0.2022, 0.1693, 0.1728],\n",
              "        [0.3768, 0.1915, 0.1767, 0.1233, 0.1317],\n",
              "        [0.3663, 0.1933, 0.1787, 0.1267, 0.1349]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now let's compute the final output embedding"
      ],
      "metadata": {
        "id": "_fHe80-yUDKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.matmul(attention_weights,value_vectors)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lcEjQa8UJqS",
        "outputId": "7302fde1-328f-49fe-d116-18257bd94669"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0756, -0.1339, -0.3314],\n",
              "        [-1.0911, -0.1378, -0.3310],\n",
              "        [-1.1074, -0.1444, -0.3257],\n",
              "        [-1.1876, -0.1728, -0.3130],\n",
              "        [-1.1813, -0.1705, -0.3140]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Causal Attention"
      ],
      "metadata": {
        "id": "6keio-SrQ9mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_scores = attention_scores / torch.sqrt(torch.tensor(3.0))\n",
        "scaled_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_gMux2yRXdt",
        "outputId": "c266c559-c642-41f2-ce45-3fa429954bdf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4850, -0.3206, -0.3754, -0.4757, -0.4770],\n",
              "        [ 0.0088, -0.0103, -0.0469, -0.1388, -0.1302],\n",
              "        [ 0.2393,  0.1174,  0.0611, -0.1164, -0.0961],\n",
              "        [ 1.6330,  0.9562,  0.8754,  0.5156,  0.5817],\n",
              "        [ 1.5399,  0.9010,  0.8224,  0.4784,  0.5413]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_scores = torch.tril(scaled_scores)\n",
        "masked_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlR7Ybz6Rzok",
        "outputId": "2c4791ed-4768-4232-e81f-9e2015b8fd13"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4850,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0088, -0.0103,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.2393,  0.1174,  0.0611,  0.0000,  0.0000],\n",
              "        [ 1.6330,  0.9562,  0.8754,  0.5156,  0.0000],\n",
              "        [ 1.5399,  0.9010,  0.8224,  0.4784,  0.5413]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = torch.softmax(masked_scores, dim=-1)\n",
        "attention_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKefbOaVR9h9",
        "outputId": "744f5433-0143-46a9-ffac-1e8303b28489"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1334, 0.2167, 0.2167, 0.2167, 0.2167],\n",
              "        [0.2018, 0.1980, 0.2001, 0.2001, 0.2001],\n",
              "        [0.2328, 0.2060, 0.1948, 0.1832, 0.1832],\n",
              "        [0.4001, 0.2033, 0.1876, 0.1309, 0.0782],\n",
              "        [0.3663, 0.1933, 0.1787, 0.1267, 0.1349]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.matmul(attention_weights,value_vectors)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTktpNWQSJNt",
        "outputId": "8d10d381-4c24-40fa-be87-f39fc38517bb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0429, -0.1188, -0.3407],\n",
              "        [-1.0832, -0.1320, -0.3366],\n",
              "        [-1.1017, -0.1433, -0.3304],\n",
              "        [-1.2008, -0.1722, -0.3047],\n",
              "        [-1.1813, -0.1705, -0.3140]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}