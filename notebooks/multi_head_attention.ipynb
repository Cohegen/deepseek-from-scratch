{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K0_C968IqGoK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import copy\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "seaborn.set_context(context=\"talk\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of multi-head attention"
      ],
      "metadata": {
        "id": "FKRl1oKmqM5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## defining our input variable\n",
        "x = torch.randn(1,3,6)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sNbzhaVqSf3",
        "outputId": "ecbb604a-1bc5-4201-8a84-4a7d5c2d6118"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.4735,  0.1597, -1.3380,  1.9263,  1.5446,  0.8857],\n",
            "         [-0.5353, -2.0590, -0.0887,  0.3936, -0.2552, -0.5573],\n",
            "         [-0.5595,  1.0235, -0.3610,  0.5880,  1.1423, -1.6424]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPmMd0bFsDzs",
        "outputId": "17ec0687-c0b8-408e-eb85-748becfa0f88"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The shape of our embedding matrix is [1,3,6]. 1 means that our embedding matrix has a batch size of 1, has three tokens and d_in of 6.\n",
        "* Now let's calculate the head_dim"
      ],
      "metadata": {
        "id": "StQ3iHjJsRo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_q = torch.randn(6,6)\n",
        "w_k = torch.randn(6,6)\n",
        "w_v = torch.randn(6,6)\n",
        "print(w_q)\n",
        "print(w_k)\n",
        "print(w_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWKWxpRltQv2",
        "outputId": "3bdcaa58-aa09-43ba-ef85-4ae3ba7b9acf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.4236, -0.7896,  0.2153,  0.9358,  1.7820,  0.7586],\n",
            "        [-0.2089,  0.5353,  0.0289,  0.1919,  0.8375,  0.1344],\n",
            "        [-1.7585, -1.1331,  0.9242, -1.0687, -0.9793,  0.0620],\n",
            "        [-0.3945, -0.0312, -0.9360, -0.2015,  0.6547, -0.9413],\n",
            "        [-0.3483,  0.1869, -0.7988, -1.1441, -0.5444, -0.5085],\n",
            "        [-0.9239,  0.0112,  0.2564, -0.9360, -0.5950, -0.2950]])\n",
            "tensor([[-0.8277,  1.3515, -0.0028, -1.4203,  0.5166,  0.1209],\n",
            "        [-0.4109,  0.5809,  1.8617, -0.2859, -2.2864, -0.1366],\n",
            "        [-0.8955,  1.5974,  0.3516, -0.4752, -1.2126, -1.3231],\n",
            "        [-0.4409, -0.6348,  0.1634,  1.1214, -0.0749, -0.4081],\n",
            "        [-1.3281,  0.1743,  1.8257, -1.6399,  0.5695, -0.4977],\n",
            "        [-0.9622, -0.2941,  1.3717, -0.7383,  1.5301, -0.9479]])\n",
            "tensor([[ 0.5557,  0.6057,  0.4444,  0.4568,  0.3508,  1.5324],\n",
            "        [ 0.8020,  0.1285, -1.4518,  0.5329,  0.0419,  1.3991],\n",
            "        [-0.9131,  1.2236,  0.2359, -1.7598, -0.1423,  0.2901],\n",
            "        [-0.0852, -0.2009,  0.4286, -0.3846,  0.2975,  1.7494],\n",
            "        [ 1.1802,  0.1595,  1.2669, -1.5589, -0.1773, -0.7053],\n",
            "        [-0.2981, -0.1995, -1.4019,  0.8082, -0.0109,  1.2950]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculating query,key and value vectors of our input embedding\n",
        "q = torch.matmul(x,w_q)\n",
        "k = torch.matmul(x,w_k)\n",
        "v = torch.matmul(x,w_v)\n",
        "\n",
        "print(\"query vector:\\n\",q)\n",
        "print(\"key vector:\\n\",k)\n",
        "print(\"value vector:\\n\",v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jsv--f5toLx",
        "outputId": "de217219-3509-4be4-c878-bfa3a2882f8e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query vector:\n",
            " tensor([[[ 3.7744,  0.6766, -3.7243, -0.1449,  3.9631, -1.8036],\n",
            "         [-0.2627, -0.6452, -0.5642, -0.0670, -1.8633, -0.7646],\n",
            "         [-0.0472,  1.5755, -2.3085,  0.1706,  0.9542, -0.9591]]])\n",
            "key vector:\n",
            " tensor([[[-3.8398, -1.2673,  4.1725, -2.5294,  4.1091, -0.4678],\n",
            "         [ 2.0701, -2.1916, -5.0290,  2.6623,  3.5114,  0.8285],\n",
            "         [ 0.1700, -0.4296,  1.7086,  0.6723, -4.0978,  1.0186]]])\n",
            "value vector:\n",
            " tensor([[[ 3.5635, -1.0415,  1.6482,  0.6800,  1.0036,  5.5205],\n",
            "         [-2.0365, -0.7059,  3.3572, -1.3898, -0.0931, -3.5801],\n",
            "         [ 2.6271, -0.2575,  2.1821, -2.4089, -0.1117, -1.4339]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys  = keys.view(b,)"
      ],
      "metadata": {
        "id": "TYVujghTzmi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert (d_out % num_heads == 0), \\\n",
        "       \"d_out must be divisible by num_heads\"\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out, d_out) # linear layer to combine head output\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.tril(torch.ones(context_length,context_length), diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    b, num_tokens,d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    #"
      ],
      "metadata": {
        "id": "rZBP9w-wuvS2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}