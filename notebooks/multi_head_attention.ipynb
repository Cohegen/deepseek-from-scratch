{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K0_C968IqGoK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import copy\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "seaborn.set_context(context=\"talk\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of multi-head attention"
      ],
      "metadata": {
        "id": "FKRl1oKmqM5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## defining our input variable\n",
        "x = torch.randn(1,3,6)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sNbzhaVqSf3",
        "outputId": "386df009-9d74-4f1f-ed27-8ffd5a1dbc64"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.2851,  0.0689,  0.5441, -0.0941, -0.7290,  0.4415],\n",
            "         [-1.6659,  0.3111, -1.2321,  1.6866, -2.0077,  0.5211],\n",
            "         [ 0.9060,  1.1238, -0.5217, -0.3128,  1.2894,  1.1534]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPmMd0bFsDzs",
        "outputId": "493b55f8-f4a8-45ea-a9f2-4a1f9461884a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The shape of our embedding matrix is [1,3,6]. 1 means that our embedding matrix has a batch size of 1, has three tokens and d_in of 6.\n",
        "* Now let's calculate the head_dim"
      ],
      "metadata": {
        "id": "StQ3iHjJsRo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_q = torch.randn(6,6)\n",
        "w_k = torch.randn(6,6)\n",
        "w_v = torch.randn(6,6)\n",
        "print(w_q)\n",
        "print(w_k)\n",
        "print(w_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWKWxpRltQv2",
        "outputId": "a5236f41-6a75-4a82-c93f-79c8f5cf98ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8967,  0.3720,  0.7535, -2.1120, -0.6774, -0.0399],\n",
            "        [-1.9073,  1.5266,  0.1816,  0.0970, -0.4176,  0.8444],\n",
            "        [-0.4699, -1.1347,  0.7681, -0.0721,  0.8910,  0.9507],\n",
            "        [ 0.3501, -2.5955,  0.7957,  0.8863,  1.1494, -0.7801],\n",
            "        [-0.7152, -0.1136, -0.8741, -0.4199,  0.6200, -0.0035],\n",
            "        [-0.0411, -0.0320, -1.9584, -0.4949,  0.2590, -1.3881]])\n",
            "tensor([[ 0.8658,  0.4797,  1.6069,  0.7115,  0.4459, -0.1898],\n",
            "        [ 0.6261,  0.5471,  0.4684,  0.5704,  1.2109,  2.0190],\n",
            "        [ 0.3319,  1.2252, -0.3378, -0.4697, -0.6574, -0.4810],\n",
            "        [-1.8914, -2.3508,  0.4883,  1.0043,  0.9003, -0.0177],\n",
            "        [ 0.4347,  0.3509, -0.2219,  1.2907, -0.8218, -2.1762],\n",
            "        [ 1.0719,  0.1443,  1.2829, -0.3455, -0.6673,  0.4915]])\n",
            "tensor([[ 1.1864, -0.8665,  0.4948,  1.0562, -0.3337,  0.8361],\n",
            "        [ 0.4017, -0.4543,  1.1050, -1.5086,  0.6530, -2.5984],\n",
            "        [ 1.1178, -0.0788, -0.3701, -0.1889, -0.1921,  2.5239],\n",
            "        [-0.2591,  1.7034, -0.5846,  0.3413, -0.3829, -0.1810],\n",
            "        [ 0.7335, -0.3465,  1.4526, -0.1774,  0.4421,  0.6721],\n",
            "        [-3.3235, -1.7699, -0.5768,  0.5240,  0.7169,  0.8661]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculating query,key and value vectors of our input embedding\n",
        "q = torch.matmul(x,w_q)\n",
        "k = torch.matmul(x,w_k)\n",
        "v = torch.matmul(x,w_v)\n",
        "\n",
        "print(\"query vector:\\n\",q)\n",
        "print(\"key vector:\\n\",k)\n",
        "print(\"value vector:\\n\",v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jsv--f5toLx",
        "outputId": "5cd1451d-f015-49e5-e8ba-f44aa8351249"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query vector:\n",
            " tensor([[[-1.0691,  0.2787,  1.0963, -2.7425, -0.8602, -0.0129],\n",
            "         [ 3.4841, -2.9129, -0.0688,  5.7173,  0.7295, -2.8742],\n",
            "         [-3.7898,  3.2731, -3.1487, -3.1563, -0.8091, -0.9448]]])\n",
            "key vector:\n",
            " tensor([[[ 1.6707e+00,  1.3500e+00,  2.5958e+00, -4.8993e-01,  5.1850e-01,\n",
            "           1.4385e+00],\n",
            "         [-5.1605e+00, -6.7326e+00, -1.7743e-01, -1.5066e+00,  3.2645e+00,\n",
            "           6.1325e+00],\n",
            "         [ 3.7034e+00,  1.7645e+00,  3.1995e+00,  2.4821e+00, -3.2199e-03,\n",
            "           1.1429e-01]]])\n",
            "value vector:\n",
            " tensor([[[ 0.1827, -1.8770, -0.7480,  1.4792, -0.4581,  2.1782],\n",
            "         [-6.8700,  4.0457, -4.2274, -0.7914, -0.1641, -6.5143],\n",
            "         [-1.8634, -4.2756,  3.2738, -0.3711,  2.0484, -1.5570]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert (d_out % num_heads == 0), \\\n",
        "       \"d_out must be divisible by num_heads\"\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out, d_out) # linear layer to combine head output\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.tril(torch.ones(context_length,context_length), diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    b, num_tokens,d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    #splitting the matrix by adding a `num_heads` dimension\n",
        "    ## unroll last dim: (b,num_tokens,d_out) -> (b,num_tokens,num_heads,head_dim)\n",
        "    keys = keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    queries = queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    values = values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "\n",
        "    ##transpose : (b,um_tokens,num_heads,head_dim) to (b,num_heads,num_tokens,head_dim)\\\n",
        "    ##grouping in terms of heads\n",
        "    keys = keys.transpose(1,2)\n",
        "    queries = queries.transpose(1,2)\n",
        "    values = values.transpose(1,2)\n",
        "\n",
        "    ##computing scaled dot-product attention\n",
        "    attn_scores = queries @ keys.transpose(2,3)\n",
        "\n",
        "    #original mask teucated to the number of the tokens and converted to boolean\n",
        "    mask_bool = self.mask.bool()[:num_tokens, : num_tokens]\n",
        "\n",
        "    #use the mask to fill attention scores\n",
        "    attn_scores = attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    ##combining heads,where self.d_out = self.num_heads * self.head_dim\n",
        "    context_vec = context_vec.contiguous().view(b,num_tokens,self.d_out)\n",
        "    context_vec = self.out_proj(context_vec) #optional projection\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "rZBP9w-wuvS2"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}